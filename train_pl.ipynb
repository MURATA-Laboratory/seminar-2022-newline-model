{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJPKJpeQRcp7"
      },
      "source": [
        "# 改行・読点挿入モデル 学習ノートブック\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3QeER9aSAt_"
      },
      "source": [
        "## Mount\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2S5T6ThmR5cK",
        "outputId": "72bba765-6558-4a9f-d672-78306c1f8ea5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhaPZCrtRcqA"
      },
      "source": [
        "## Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1oSz-glRhRQ",
        "outputId": "d550ab5b-65ba-40bc-e177-bc1c0818cd39"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install wandb\n",
        "!pip install pytorch-lightning\n",
        "!pip install rich\n",
        "!pip install python-box\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0nDiORbGRcqB"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torchmetrics\n",
        "import wandb\n",
        "from box import Box\n",
        "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, RichProgressBar\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import (\n",
        "    BertForSequenceClassification,\n",
        "    BertModel,\n",
        "    BertTokenizer,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YddZjERSgpKd"
      },
      "source": [
        "## Wandb Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlRtsjMqgpKf",
        "outputId": "a6683609-5866-4725-be4f-215b69a75e67"
      },
      "outputs": [],
      "source": [
        "wandb.login()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Vx1ELj2RcqE"
      },
      "source": [
        "## Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxLNAfUqLMAK"
      },
      "source": [
        "### Define\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIXaPYJw1iza"
      },
      "outputs": [],
      "source": [
        "TRAIN_DATASET_PATH = \"/content/drive/MyDrive/MurataLab/newline/train_dataset.csv\"\n",
        "TEST_DATASET_PATH = \"/content/drive/MyDrive/MurataLab/newline/test_dataset.csv\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbnUMPY2gpKl"
      },
      "source": [
        "### Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcD6CijhgpKl"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    INPUT_COLUMN = \"input\"\n",
        "    LF_COLUMN = \"is_line_feed\"\n",
        "    COMMA_PERIOD_COLUMN = \"comma_period\"\n",
        "\n",
        "    def __init__(self, data, tokenizer, max_token_len):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_token_len = max_token_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        data_row = self.data.iloc[index]\n",
        "        text = data_row[self.INPUT_COLUMN]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_token_len,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        return dict(\n",
        "            text=text,\n",
        "            input_ids=encoding[\"input_ids\"].flatten(),\n",
        "            attention_mask=encoding[\"attention_mask\"].flatten(),\n",
        "            labels=torch.tensor(\n",
        "                [data_row[self.LF_COLUMN], data_row[self.COMMA_PERIOD_COLUMN]]\n",
        "            ),\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARpveTkOgpKn"
      },
      "source": [
        "### DataModule\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xa43sGWLgpKn"
      },
      "outputs": [],
      "source": [
        "class DataModuleGenerator(pl.LightningDataModule):\n",
        "    \"\"\"\n",
        "    DataFrameからモデリング時に使用するDataModuleを作成\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        train_df,\n",
        "        valid_df,\n",
        "        test_df,\n",
        "        tokenizer,\n",
        "        batch_size,\n",
        "        max_token_len,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.train_df = train_df\n",
        "        self.valid_df = valid_df\n",
        "        self.test_df = test_df\n",
        "        self.batch_size = batch_size\n",
        "        self.max_token_len = max_token_len\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        self.train_dataset = CustomDataset(\n",
        "            self.train_df, self.tokenizer, self.max_token_len\n",
        "        )\n",
        "        self.valid_dataset = CustomDataset(\n",
        "            self.valid_df, self.tokenizer, self.max_token_len\n",
        "        )\n",
        "        self.test_dataset = CustomDataset(\n",
        "            self.test_df, self.tokenizer, self.max_token_len\n",
        "        )\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=1,  # FIXME: os.cpu_count()だとsweepでエラーになる\n",
        "            pin_memory=True,\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.valid_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            num_workers=1,\n",
        "            pin_memory=True,\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.test_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            num_workers=1,\n",
        "            pin_memory=True,\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfKBNtAkMap5"
      },
      "source": [
        "## Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEB6bOsVgpKo"
      },
      "outputs": [],
      "source": [
        "class MyModel(pl.LightningModule):\n",
        "    THRESHOLD = 0.5\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        tokenizer,\n",
        "        config,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.config = config\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(\n",
        "            config.pretrained_model_name, return_dict=True\n",
        "        )\n",
        "        self.bert.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "        # ラインフィードの判定 二値分類\n",
        "        self.hidden_lf_layer = torch.nn.Linear(\n",
        "            self.bert.config.hidden_size, config.model.hidden_lf_layer\n",
        "        )\n",
        "        self.lf_layer = torch.nn.Linear(config.model.hidden_lf_layer, 1)\n",
        "\n",
        "        # 挿入なし, comma, periodの判定 三値分類\n",
        "        self.hidden_comma_period_layer = torch.nn.Linear(\n",
        "            self.bert.config.hidden_size, config.model.hidden_comma_period_layer\n",
        "        )\n",
        "        self.comma_period_layer = torch.nn.Linear(\n",
        "            config.model.hidden_comma_period_layer, 3\n",
        "        )\n",
        "\n",
        "        self.lf_criterion = torch.nn.BCELoss()\n",
        "        self.comma_period_criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "        self.lf_metrics = torchmetrics.MetricCollection(\n",
        "            [\n",
        "                torchmetrics.Accuracy(task=\"binary\", threshold=self.THRESHOLD),\n",
        "                torchmetrics.Precision(task=\"binary\", threshold=self.THRESHOLD),\n",
        "                torchmetrics.Recall(task=\"binary\", threshold=self.THRESHOLD),\n",
        "                torchmetrics.F1Score(task=\"binary\", threshold=self.THRESHOLD),\n",
        "                torchmetrics.MatthewsCorrCoef(task=\"binary\", threshold=self.THRESHOLD),\n",
        "            ]\n",
        "        )\n",
        "        self.comma_period_metrics = torchmetrics.MetricCollection(\n",
        "            [\n",
        "                torchmetrics.Accuracy(task=\"multiclass\", num_classes=3),\n",
        "                torchmetrics.Precision(task=\"multiclass\", num_classes=3),\n",
        "                torchmetrics.Recall(task=\"multiclass\", num_classes=3),\n",
        "                torchmetrics.F1Score(task=\"multiclass\", num_classes=3),\n",
        "                torchmetrics.MatthewsCorrCoef(task=\"multiclass\", num_classes=3),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        # BertLayerモジュールの最後を勾配計算ありに変更\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "        for param in self.bert.encoder.layer[-1].parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        lf_outputs = torch.relu(self.hidden_lf_layer(outputs.pooler_output))\n",
        "        lf_predictions = torch.sigmoid(self.lf_layer(lf_outputs)).flatten()\n",
        "\n",
        "        comma_period_outputs = torch.relu(\n",
        "            self.hidden_comma_period_layer(outputs.pooler_output)\n",
        "        )\n",
        "        comma_period_predictions = torch.softmax(\n",
        "            self.comma_period_layer(comma_period_outputs), dim=1  # row\n",
        "        )\n",
        "\n",
        "        loss = (\n",
        "            self.compute_loss(\n",
        "                lf_predictions,\n",
        "                labels[:, 0].float(),\n",
        "                comma_period_predictions,\n",
        "                labels[:, 1].long(),\n",
        "            )\n",
        "            if labels is not None\n",
        "            else 0\n",
        "        )\n",
        "        return loss, [lf_predictions, comma_period_predictions]\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss, predictions = self.forward(\n",
        "            input_ids=batch[\"input_ids\"],\n",
        "            attention_mask=batch[\"attention_mask\"],\n",
        "            labels=batch[\"labels\"],\n",
        "        )\n",
        "        self.log(\"train/loss\", loss, on_step=True, prog_bar=True)\n",
        "        return {\n",
        "            \"loss\": loss,\n",
        "            \"batch_preds\": predictions,\n",
        "            \"batch_labels\": batch[\"labels\"],\n",
        "        }\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss, predictions = self.forward(\n",
        "            input_ids=batch[\"input_ids\"],\n",
        "            attention_mask=batch[\"attention_mask\"],\n",
        "            labels=batch[\"labels\"],\n",
        "        )\n",
        "        return {\n",
        "            \"loss\": loss,\n",
        "            \"batch_preds\": predictions,\n",
        "            \"batch_labels\": batch[\"labels\"],\n",
        "        }\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        loss, predictions = self.forward(\n",
        "            input_ids=batch[\"input_ids\"],\n",
        "            attention_mask=batch[\"attention_mask\"],\n",
        "            labels=batch[\"labels\"],\n",
        "        )\n",
        "        return {\n",
        "            \"loss\": loss,\n",
        "            \"batch_preds\": predictions,\n",
        "            \"batch_labels\": batch[\"labels\"],\n",
        "        }\n",
        "\n",
        "    def compute_loss(\n",
        "        self, lf_preds, lf_labels, comma_period_preds, comma_period_labels\n",
        "    ):\n",
        "        lf_loss = self.lf_criterion(lf_preds, lf_labels.float())\n",
        "        comma_period_loss = self.comma_period_criterion(\n",
        "            comma_period_preds, comma_period_labels.long()\n",
        "        )\n",
        "        return lf_loss + comma_period_loss  # weightsをつけることも可能\n",
        "\n",
        "    def epoch_end(self, outputs, mode):\n",
        "        epoch_lf_preds = torch.cat([x[\"batch_preds\"][0] for x in outputs])\n",
        "        epoch_lf_labels = torch.cat([x[\"batch_labels\"][:, 0] for x in outputs])\n",
        "        epoch_comma_period_preds = torch.cat([x[\"batch_preds\"][1] for x in outputs])\n",
        "        epoch_comma_period_labels = torch.cat(\n",
        "            [x[\"batch_labels\"][:, 1] for x in outputs]\n",
        "        )\n",
        "\n",
        "        epoch_loss = self.compute_loss(\n",
        "            epoch_lf_preds,\n",
        "            epoch_lf_labels,\n",
        "            epoch_comma_period_preds,\n",
        "            epoch_comma_period_labels,\n",
        "        )\n",
        "        self.log(f\"{mode}/loss\", epoch_loss, logger=True)\n",
        "\n",
        "        lf_metrics = self.lf_metrics(epoch_lf_preds, epoch_lf_labels.int())\n",
        "        for metric in lf_metrics.keys():\n",
        "            self.log(\n",
        "                f\"{mode}/lf/{metric.lower()}\", lf_metrics[metric].item(), logger=True\n",
        "            )\n",
        "\n",
        "        comma_period_metrics = self.comma_period_metrics(\n",
        "            epoch_comma_period_preds, epoch_comma_period_labels.int()\n",
        "        )\n",
        "        for metric in comma_period_metrics.keys():\n",
        "            self.log(\n",
        "                f\"{mode}/comma_period/{metric.lower()}\",\n",
        "                comma_period_metrics[metric].item(),\n",
        "                logger=True,\n",
        "            )\n",
        "\n",
        "        return (\n",
        "            epoch_lf_preds,\n",
        "            epoch_lf_labels,\n",
        "            epoch_comma_period_preds,\n",
        "            epoch_comma_period_labels,\n",
        "        )\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        self.epoch_end(outputs, \"val\")\n",
        "\n",
        "    def test_epoch_end(self, outputs):\n",
        "        lf_preds, lf_labels, comma_period_preds, comma_period_labels = self.epoch_end(\n",
        "            outputs, \"test\"\n",
        "        )\n",
        "        lf_preds, lf_labels, comma_period_preds, comma_period_labels = (\n",
        "            lf_preds.cpu().numpy(),\n",
        "            lf_labels.cpu().numpy(),\n",
        "            comma_period_preds.cpu().numpy(),\n",
        "            comma_period_labels.cpu().numpy(),\n",
        "        )\n",
        "        lf_preds, comma_period_preds = (\n",
        "            np.where(lf_preds > self.THRESHOLD, 1, 0),\n",
        "            np.argmax(comma_period_preds, axis=1),\n",
        "        )\n",
        "\n",
        "        wandb.log(\n",
        "            {\n",
        "                \"test/lf/confusion_matrix\": wandb.plot.confusion_matrix(\n",
        "                    probs=None,\n",
        "                    y_true=lf_labels,\n",
        "                    preds=lf_preds,\n",
        "                    class_names=[\"-\", \"改行\"],\n",
        "                ),\n",
        "                \"test/comma_period/confusion_matrix\": wandb.plot.confusion_matrix(\n",
        "                    probs=None,\n",
        "                    y_true=comma_period_labels,\n",
        "                    preds=comma_period_preds,\n",
        "                    class_names=[\"挿入なし\", \"読点\", \"句点\"],\n",
        "                ),\n",
        "            }\n",
        "        )\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        assert self.config.optimizer.name in [\"AdamW\", \"RAdam\"]\n",
        "        if self.config.optimizer.name == \"AdamW\":\n",
        "            optimizer = torch.optim.AdamW(\n",
        "                self.parameters(),\n",
        "                lr=self.config.optimizer.lr,\n",
        "            )\n",
        "        elif self.config.optimizer.name == \"RAdam\":\n",
        "            optimizer = torch.optim.RAdam(\n",
        "                self.parameters(),\n",
        "                lr=self.config.optimizer.lr,\n",
        "            )\n",
        "        return [optimizer]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDSSe4bNgpKr"
      },
      "source": [
        "## Train Runner\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 705,
          "referenced_widgets": [
            "c05e2cb90d4c4b669c03a79e53cef684",
            "ea3752abd970401280e24ba5c31f6dee"
          ]
        },
        "id": "NxJpWSkZgpKr",
        "outputId": "c7966d4a-736c-4fc2-e99e-45bf0cefbb44"
      },
      "outputs": [],
      "source": [
        "class MyTrainer:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "\n",
        "    def execute(self):\n",
        "        current = (datetime.datetime.now() + datetime.timedelta(hours=9)).strftime(\n",
        "            \"%Y%m%d_%H%M%S\"\n",
        "        )\n",
        "        MODEL_OUTPUT_DIR = \"/content/drive/MyDrive/MurataLab/newline/models/\" + current\n",
        "        os.makedirs(MODEL_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "        wandb.init(\n",
        "            project=self.config.wandb_project_name,\n",
        "            name=current,\n",
        "            config=self.config,\n",
        "            id=current,\n",
        "            save_code=True,\n",
        "        )\n",
        "        config = Box(dict(wandb.config))\n",
        "\n",
        "        tokenizer = BertTokenizer.from_pretrained(config.pretrained_model_name)\n",
        "        tokenizer.add_tokens([\"[ANS]\"])\n",
        "\n",
        "        train_df, val_df = train_test_split(\n",
        "            pd.read_csv(TRAIN_DATASET_PATH),\n",
        "            train_size=config.data.train_rate,\n",
        "            random_state=config.seed,\n",
        "        )\n",
        "        test_df = pd.read_csv(TEST_DATASET_PATH)\n",
        "\n",
        "        data_module = DataModuleGenerator(\n",
        "            train_df=train_df,\n",
        "            valid_df=val_df,\n",
        "            test_df=test_df,\n",
        "            tokenizer=tokenizer,\n",
        "            batch_size=config.data_module.batch_size,\n",
        "            max_token_len=config.data_module.max_length,\n",
        "        )\n",
        "        data_module.setup()\n",
        "\n",
        "        model = MyModel(\n",
        "            tokenizer,\n",
        "            config=config,\n",
        "        )\n",
        "\n",
        "        early_stop_callback = EarlyStopping(\n",
        "            **config.early_stopping,\n",
        "        )\n",
        "\n",
        "        wandb_logger = WandbLogger(\n",
        "            log_model=False,\n",
        "        )\n",
        "        wandb_logger.watch(model, log=\"all\")\n",
        "\n",
        "        checkpoint_callback = ModelCheckpoint(\n",
        "            dirpath=MODEL_OUTPUT_DIR,\n",
        "            **config.checkpoint,\n",
        "        )\n",
        "\n",
        "        progress_bar = RichProgressBar()\n",
        "\n",
        "        trainer = pl.Trainer(\n",
        "            max_epochs=config.epoch,\n",
        "            accelerator=\"auto\",\n",
        "            devices=\"auto\",\n",
        "            callbacks=[checkpoint_callback, early_stop_callback, progress_bar],\n",
        "            logger=wandb_logger,\n",
        "        )\n",
        "\n",
        "        trainer.fit(model, data_module)\n",
        "\n",
        "        trainer.test(model, data_module)\n",
        "\n",
        "        wandb.finish()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DO_SWEEP = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = dict(\n",
        "    wandb_project_name=\"lf-comma-period-v2\",\n",
        "    pretrained_model_name=\"cl-tohoku/bert-base-japanese-whole-word-masking\",\n",
        "    epoch=4,\n",
        "    seed=40,\n",
        "    data_module=dict(\n",
        "        batch_size=16,\n",
        "        max_length=32,\n",
        "    ),\n",
        "    optimizer=dict(\n",
        "        name=\"AdamW\",\n",
        "        lr=2e-5,\n",
        "    ),\n",
        "    data=dict(\n",
        "        train_rate=0.8,\n",
        "    ),\n",
        "    model=dict(\n",
        "        hidden_lf_layer=64,\n",
        "        hidden_comma_period_layer=64,\n",
        "    ),\n",
        "    early_stopping=dict(\n",
        "        monitor=\"val/loss\",\n",
        "        patience=3,\n",
        "        mode=\"min\",\n",
        "        min_delta=0.02,\n",
        "    ),\n",
        "    checkpoint=dict(\n",
        "        monitor=\"val/loss\",\n",
        "        mode=\"min\",\n",
        "        filename=\"{epoch}\",\n",
        "        verbose=True,\n",
        "    ),\n",
        ")\n",
        "config = Box(config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sweep_config = dict(\n",
        "    method=\"random\",\n",
        "    metric=dict(\n",
        "        goal=\"minimize\",\n",
        "        name=\"val/loss\",\n",
        "    ),\n",
        "    parameters=dict(\n",
        "        data_module=dict(\n",
        "            parameters=dict(\n",
        "                batch_size=dict(\n",
        "                    values=[16, 32, 64],\n",
        "                ),\n",
        "                max_length=dict(\n",
        "                    value=32,\n",
        "                ),\n",
        "            )\n",
        "        ),\n",
        "        optimizer=dict(\n",
        "            parameters=dict(\n",
        "                name=dict(\n",
        "                    values=[\"AdamW\", \"RAdam\"],\n",
        "                ),\n",
        "                lr=dict(\n",
        "                    values=[1e-5, 5e-5, 9e-5, 1e-6],\n",
        "                ),\n",
        "            ),\n",
        "        ),\n",
        "        model=dict(\n",
        "            parameters=dict(\n",
        "                hidden_lf_layer=dict(\n",
        "                    values=[128, 256, 512],\n",
        "                ),\n",
        "                hidden_comma_period_layer=dict(\n",
        "                    values=[64, 128, 256],\n",
        "                ),\n",
        "            )\n",
        "        ),\n",
        "    ),\n",
        ")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Execute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if DO_SWEEP:\n",
        "    sweep_id = wandb.sweep(sweep_config, project=config.wandb_project_name)\n",
        "    trainer = MyTrainer(config)\n",
        "    wandb.agent(sweep_id, trainer.execute, count=10)\n",
        "else:\n",
        "    trainer = MyTrainer(config)\n",
        "    trainer.execute()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxkdyZvonyMn"
      },
      "source": [
        "## Predict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rgcSo7inyMn",
        "outputId": "d19e279a-4c70-4522-9e2c-edb80eda6ef8"
      },
      "outputs": [],
      "source": [
        "MODEL_DIR = \"/content/drive/MyDrive/MurataLab/newline/models\"\n",
        "id = input(\"id (2022XXXX_XXXXXX) : \")\n",
        "epoch = input(\"epoch: \")\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(config.pretrained_model_name)\n",
        "tokenizer.add_tokens([\"[ANS]\"])\n",
        "\n",
        "model = MyModel(\n",
        "    tokenizer,\n",
        "    config=config,\n",
        ")\n",
        "model.load_state_dict(\n",
        "    torch.load(os.path.join(MODEL_DIR, id, f\"epoch={epoch}.ckpt\"))[\"state_dict\"]\n",
        ")\n",
        "model.eval()\n",
        "model.freeze()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCplOxXVnyMo",
        "outputId": "4f52399a-5efa-4a23-b80b-00b1f057e044"
      },
      "outputs": [],
      "source": [
        "threshold = 0.5\n",
        "\n",
        "while True:\n",
        "    text = input(\"Text [or exit]: \")\n",
        "    if text == \"exit\":\n",
        "        break\n",
        "\n",
        "    t0 = time.time()\n",
        "    encoding = tokenizer.encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=config.data_module.max_length,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    predictions = model(\n",
        "        input_ids=encoding[\"input_ids\"],\n",
        "        attention_mask=encoding[\"attention_mask\"],\n",
        "    )[1]\n",
        "    print(f\"[Time: {time.time() - t0:.2f} sec]\")\n",
        "    print(predictions)\n",
        "\n",
        "    print(text.split(\"[ANS]\")[0], end=\"\")\n",
        "    if np.argmax(predictions[1]) == 1:\n",
        "        print(\"、\", end=\"\")\n",
        "    elif np.argmax(predictions[1]) == 2:\n",
        "        print(\"。\", end=\"\")\n",
        "    if predictions[0] > threshold:\n",
        "        print(\"\")\n",
        "    print(text.split(\"[ANS]\")[1], end=\"\\n\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5 (main, Jul  7 2022, 20:58:07) [Clang 12.0.5 (clang-1205.0.22.11)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "294252db5989f7e12b7215c0f64397d9acb0d211d5f7e00aa1e71c3fd3e5557d"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "232d060aa8a749d687fb72926250abd2": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_8d7756235e7a49ceaa425794e4cf28e2",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Testing</span> <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">89/89</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:00:03 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">24.69it/s</span>  \n</pre>\n",
                  "text/plain": "\u001b[37mTesting\u001b[0m \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m89/89\u001b[0m \u001b[38;5;245m0:00:03 • 0:00:00\u001b[0m \u001b[38;5;249m24.69it/s\u001b[0m  \n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "8d7756235e7a49ceaa425794e4cf28e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c05e2cb90d4c4b669c03a79e53cef684": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_ea3752abd970401280e24ba5c31f6dee",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 3/3  <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">1385/1385</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">0:01:15 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">18.49it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">loss: 0.563 v_num: 1014          </span>\n                                                                                  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">train/loss: 0.505                </span>\n</pre>\n",
                  "text/plain": "Epoch 3/3  \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m1385/1385\u001b[0m \u001b[38;5;245m0:01:15 • 0:00:00\u001b[0m \u001b[38;5;249m18.49it/s\u001b[0m \u001b[37mloss: 0.563 v_num: 1014          \u001b[0m\n                                                                                  \u001b[37mtrain/loss: 0.505                \u001b[0m\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "ea3752abd970401280e24ba5c31f6dee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
